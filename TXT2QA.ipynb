{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2467a5-854b-42d7-87c5-45c833a5e727",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for gpt-3.5-turbo in organization org-6QBVtVwtyUGQzVXoQ7ScNa1d on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12254/2972025837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         ]\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for gpt-3.5-turbo in organization org-6QBVtVwtyUGQzVXoQ7ScNa1d on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "\n",
    "# 设置您的OpenAI API密钥。\n",
    "openai.api_key = 'YOUR API KEY'\n",
    "\n",
    "# 读取数据集\n",
    "df = pd.read_parquet('Cuted_TD/subset_6.parquet')\n",
    "\n",
    "# 开始计时\n",
    "start_time = time.time()\n",
    "\n",
    "# 打开一个文件以准备写入\n",
    "with open('qa_pairs6.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(\"[\\n\")  # 开始一个JSON数组\n",
    "\n",
    "    first_item = True  # 用于跟踪是否是第一个条目，以避免在第一个条目前添加逗号\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        data_id = row['ID']\n",
    "        title = row['title']\n",
    "        abstract = row['abstract']\n",
    "        content = title + \".\" + abstract  # 合并title和abstract为content\n",
    "\n",
    "        \n",
    "                \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Given the title: \\\"{title}\\\" and abstract: \\\"{abstract}\\\". Given the above content, ask an AI-related question based on the title and generate an answer based on the abstract in JSON format [question: What/How xxx ?, answer: xxx. ].you need to put only quotation marks around the contents of the question and answer.The question should be less than 25 tokens and the answer between 100 to 200 tokens.\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "\n",
    "        response_content = response.choices[0].message['content']\n",
    "\n",
    "        try:\n",
    "            # 这里添加代码解析response_content中的问题和答案\n",
    "            qa_content = eval(response_content)\n",
    "        except:\n",
    "            qa_content = {\"question\": \"\", \"answer\": \"\"}  # 如果解析失败，使用空字符串\n",
    "\n",
    "        qa_pair_with_id = {\n",
    "            \"id\": data_id,\n",
    "            \"context\": content,\n",
    "            \"question\": qa_content[\"question\"],\n",
    "            \"answer\": qa_content[\"answer\"]\n",
    "        }\n",
    "\n",
    "        # 如果不是第一项，添加一个逗号来分隔项目\n",
    "        if not first_item:\n",
    "            json_file.write(\",\\n\")\n",
    "        else:\n",
    "            first_item = False\n",
    "\n",
    "        # 将新的问题答案对（包含ID和content）写入文件\n",
    "        json.dump(qa_pair_with_id, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    json_file.write(\"\\n]\")  # 结束JSON数组\n",
    "\n",
    "# 打印用时\n",
    "print(\"Total time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8abf222-2cf2-45e7-9554-0a22946af566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 121.6242618560791\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "\n",
    "# 设置您的OpenAI API密钥。\n",
    "openai.api_key = 'YOUR API KEY'\n",
    "# openai.api_key = 'YOUR API KEY'\n",
    "\n",
    "# 读取数据集\n",
    "df = pd.read_parquet('Cuted_TD/subset_6.parquet')\n",
    "\n",
    "# 开始计时\n",
    "start_time = time.time()\n",
    "\n",
    "# 找到ID为21727的数据的索引\n",
    "start_index = df.index[df['ID'] == 74028].tolist()#断开的ID加1\n",
    "if start_index:\n",
    "    start_index = start_index[0]  # 获取ID为21727的数据的索引\n",
    "else:\n",
    "    print(\"ID not found.\")\n",
    "    start_index = len(df)  # 如果没有找到，不处理任何数据\n",
    "\n",
    "# 从ID为21727的数据开始处理\n",
    "df = df.iloc[start_index:]\n",
    "\n",
    "# 以读取模式打开现有的JSON文件来获取内容\n",
    "try:\n",
    "    with open('qa_pairs6.json', 'r', encoding='utf-8') as file:\n",
    "        content = file.read().rstrip('\\n')\n",
    "        # 检查是否需要在末尾添加逗号\n",
    "        needs_comma = not content.endswith('[') and content != \"\"\n",
    "except FileNotFoundError:\n",
    "    needs_comma = False  # 文件不存在时，不需要添加逗号\n",
    "\n",
    "# 再次以追加模式打开文件以添加新内容\n",
    "with open('qa_pairs6.json', 'a', encoding='utf-8') as json_file:\n",
    "    if needs_comma:\n",
    "        # 如果文件已存在内容，先添加逗号和换行\n",
    "        json_file.write(\",\\n\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        data_id = row['ID']\n",
    "        title = row['title']\n",
    "        abstract = row['abstract']\n",
    "        content = title + \".\" + abstract\n",
    "                \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Given the title: \\\"{title}\\\" and abstract: \\\"{abstract}\\\". Given the above content, ask an AI-related question based on the title and generate an answer based on the abstract in JSON format [question: What/How xxx ?, answer: xxx. ].You need to put only quotation marks around the contents of the question and answer.The question should be less than 25 tokens and the answer between 100 to 200 tokens.\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "\n",
    "        response_content = response.choices[0].message['content']\n",
    "\n",
    "        try:\n",
    "            # 这里添加代码解析response_content中的问题和答案\n",
    "            qa_content = eval(response_content)\n",
    "        except:\n",
    "            qa_content = {\"question\": \"\", \"answer\": \"\"}  # 如果解析失败，使用空字符串\n",
    "\n",
    "        qa_pair_with_id = {\n",
    "            \"id\": data_id,\n",
    "            \"context\": content,\n",
    "            \"question\": qa_content[\"question\"],\n",
    "            \"answer\": qa_content[\"answer\"]\n",
    "        }\n",
    "\n",
    "        # 写入新的数据对象\n",
    "        json.dump(qa_pair_with_id, json_file, ensure_ascii=False, indent=4)\n",
    "        json_file.write(\",\\n\")  # 每个对象后添加逗号和换行符\n",
    "\n",
    "    # 由于是追加模式，我们在文件最后处理结束符\n",
    "    # 不需要回退和删除最后的逗号，因为我们将在下一次追加之前处理它\n",
    "\n",
    "# 在所有数据处理完毕后，关闭数组（如果需要的话可以在下一次打开文件时处理）\n",
    "# 打印用时\n",
    "print(\"Total time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91011ad1-8ad2-493f-b902-adbd9abe35c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59afea-9b73-4b58-9264-789e14b3f245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
